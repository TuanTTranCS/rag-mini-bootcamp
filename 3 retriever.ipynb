{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrievers & retrievers.py\n",
    "In order to retrieve relevant chunks of text from the vector database, we must first vectorize our query using the same model we created our text chunk embeddings with. We then give that query vector to the vector database. The vector database uses the query vector to perform a cosine similarity search for the most similar text chunks.\n",
    "\n",
    "If you've already run your indexer, the below code should work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reliance on pre-training data, it initially lacks the capacity to provide updates on recent developments. RAG bridges this information gap by sourcing and incorporating knowledge from external databases. In this case, it gathers relevant news articles related to the user’s query. These articles, combined with the original question, form a comprehensive prompt that empowers LLMs to generate a well-informed answer. The RAG research paradigm is continuously evolving, and we categorize it into three stages: Naive RAG, Advanced RAG, and Modular RAG, as showed in Figure3. Despite RAG method are cost-effective and surpass the performance of the native LLM, they also exhibit several limitations. The development of Advanced RAG and Modular RAG is a response to these specific shortcomings in Naive RAG. II-ANaive RAG The Naive RAG research paradigm represents the earliest methodology, which gained prominence shortly after the widespread adoption of ChatGPT. The Naive RAG follows a traditional pro\n",
      "\n",
      "====================================\n",
      "\n",
      "approaches in their respective contexts, and speculate on upcoming trends and innovations. Our contributions are as follows: In this survey, we present a thorough and systematic review of the state-of-the-art RAG methods, delineating its evolution through paradigms including naive RAG, advanced RAG, and modular RAG. This review contextualizes the broader scope of RAG research within the landscape of LLMs. We identify and discuss the central technologies integral to the RAG process, specifically focusing on the aspects of “Retrieval”, “Generation” and “Augmentation”, and delve into their synergies, elucidating how these components intricately collaborate to form a cohesive and effective RAG framework. We have summarized the current assessment methods of RAG, covering 26 tasks, nearly 50 datasets, outlining the evaluation objectives and metrics, as well as the current evaluation benchmarks and tools. Additionally, we anticipate future directions for RAG, emphasizing potential enhancement\n"
     ]
    }
   ],
   "source": [
    "from cheat_code.common_components.vectorizers import Vectorizer\n",
    "from cheat_code.common_components.vectordb_client_adapters import CouchbaseClientAdapter\n",
    "\n",
    "vectorizer = Vectorizer()\n",
    "client_adapter = CouchbaseClientAdapter()\n",
    "\n",
    "query = \"How is Naive RAG different from Advanced RAG?\"\n",
    "query_vector = vectorizer.vectorize_query(query)\n",
    "retrieved_chunks_list = client_adapter.retrieve(query_vector, k=2)\n",
    "\n",
    "print(retrieved_chunks_list[0][0:1000])\n",
    "print(\"\\n====================================\\n\")\n",
    "print(retrieved_chunks_list[1][0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retriever task #1: implement vectorize_query() in workshop_code/common_components/vectorizers.py\n",
    "This should be easy because it's essentially a simpler version of `vectorize_text_chunks()`, which you've already completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reliance on pre-training data, it initially lacks the capacity to provide updates on recent developments. RAG bridges this information gap by sourcing and incorporating knowledge from external databases. In this case, it gathers relevant news articles related to the user’s query. These articles, combined with the original question, form a comprehensive prompt that empowers LLMs to generate a well-informed answer. The RAG research paradigm is continuously evolving, and we categorize it into three stages: Naive RAG, Advanced RAG, and Modular RAG, as showed in Figure3. Despite RAG method are cost-effective and surpass the performance of the native LLM, they also exhibit several limitations. The development of Advanced RAG and Modular RAG is a response to these specific shortcomings in Naive RAG. II-ANaive RAG The Naive RAG research paradigm represents the earliest methodology, which gained prominence shortly after the widespread adoption of ChatGPT. The Naive RAG follows a traditional pro\n",
      "\n",
      "====================================\n",
      "\n",
      "approaches in their respective contexts, and speculate on upcoming trends and innovations. Our contributions are as follows: In this survey, we present a thorough and systematic review of the state-of-the-art RAG methods, delineating its evolution through paradigms including naive RAG, advanced RAG, and modular RAG. This review contextualizes the broader scope of RAG research within the landscape of LLMs. We identify and discuss the central technologies integral to the RAG process, specifically focusing on the aspects of “Retrieval”, “Generation” and “Augmentation”, and delve into their synergies, elucidating how these components intricately collaborate to form a cohesive and effective RAG framework. We have summarized the current assessment methods of RAG, covering 26 tasks, nearly 50 datasets, outlining the evaluation objectives and metrics, as well as the current evaluation benchmarks and tools. Additionally, we anticipate future directions for RAG, emphasizing potential enhancement\n"
     ]
    }
   ],
   "source": [
    "from workshop_code.common_components.vectorizers import Vectorizer\n",
    "from workshop_code.common_components.vectordb_client_adapters import CouchbaseClientAdapter\n",
    "\n",
    "vectorizer = Vectorizer()\n",
    "client_adapter = CouchbaseClientAdapter()\n",
    "\n",
    "query = \"How is Naive RAG different from Advanced RAG?\"\n",
    "query_vector = vectorizer.vectorize_query(query)\n",
    "retrieved_chunks_list = client_adapter.retrieve(query_vector, k=2)\n",
    "\n",
    "print(retrieved_chunks_list[0][0:1000])\n",
    "print(\"\\n====================================\\n\")\n",
    "print(retrieved_chunks_list[1][0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retriever task #2: understand `retrievers.py`\n",
    "Look over the code of `retrievers.py`. If something doesn't make sense, ask one of us."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
