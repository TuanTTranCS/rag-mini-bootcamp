{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "def display_md(content):\n",
    "  display(Markdown(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generators and generators.py\n",
    "Now that you've retrieved the context needed for your query, the only step left is to prompt your LLM with the retrieved context appropriately. In a production setting, you may spend some time optimizing your prompt with techniques like Chain of Thought or using prompt compilation with DSPy. Generally, the better the inference performance you are trying to get out of a smaller model, the more optimization you will have to do to achieve acceptable performance.\n",
    "\n",
    "The following cheat code should work if you're run your indexer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cheat_code.common_components.vectorizers import Vectorizer\n",
    "from cheat_code.retrievers import NaiveRetriever\n",
    "from cheat_code.generators import NaiveGenerator\n",
    "\n",
    "vectorizer = Vectorizer()\n",
    "retriever = NaiveRetriever(vectorizer)\n",
    "generator = NaiveGenerator()\n",
    "\n",
    "query = \"What's the difference between Naive RAG and Advanced RAG?\"\n",
    "retrieved_context = retriever.retrieve(query)\n",
    "completion = generator.get_completion(query, retrieved_context)\n",
    "display_md(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Write a system prompt and prompt for the LLM that combines your query with the retrieved context\n",
    "Modify the code in `./workshop_code/generators.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workshop_code.common_components.vectorizers import Vectorizer\n",
    "from workshop_code.retrievers import NaiveRetriever\n",
    "from workshop_code.generators import NaiveGenerator\n",
    "\n",
    "vectorizer = Vectorizer()\n",
    "retriever = NaiveRetriever(vectorizer)\n",
    "generator = NaiveGenerator()\n",
    "\n",
    "query = \"What's the difference between Naive RAG and Advanced RAG?\"\n",
    "retrieved_context = retriever.retrieve(query)\n",
    "completion = generator.get_completion(query, retrieved_context)\n",
    "display_md(completion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
